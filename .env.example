# Environment Configuration Template
# Copy to .env and configure based on your deployment

# ====================================
# DEPLOYMENT ENVIRONMENT
# ====================================
# Environment: "local", "staging", "production"
ENVIRONMENT=local
# Deployment target: "docker-compose", "eks", "ecs"
DEPLOYMENT_TARGET=docker-compose

# ====================================
# DATABASE CONFIGURATION
# ====================================
# Database connection (unified for all services)
DATABASE_URL=postgresql://cicd_assistant:secure_password@postgres-assistant:5432/cicd_assistant

# For EKS: Use individual components for K8s secrets
DB_HOST=postgres-assistant
DB_PORT=5432
DB_NAME=cicd_assistant
DB_USER=cicd_assistant
DB_PASSWORD=secure_password

# Connection pool settings
DB_POOL_MIN_SIZE=2
DB_POOL_MAX_SIZE=10

# ====================================
# QUEUE CONFIGURATION
# ====================================
# Queue type: "rabbitmq", "redis", "sqs", "none"
QUEUE_TYPE=rabbitmq

# Queue connection URLs (unified)
RABBITMQ_URL=amqp://admin:admin@rabbitmq:5672
REDIS_URL=redis://redis:6379/0
QUEUE_NAME=webhook-events

# AWS SQS (for EKS deployment)
SQS_QUEUE_URL=
SQS_REGION=us-east-1

# ====================================
# VECTOR STORE CONFIGURATION
# ====================================
# Vector store type: "opensearch-local", "opensearch-aws", "disabled"
VECTOR_STORE_TYPE=opensearch-local

# OpenSearch connection
OPENSEARCH_HOST=opensearch
OPENSEARCH_PORT=9200
OPENSEARCH_USE_SSL=false
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=
OPENSEARCH_INDEX=cicd-fixes

# AWS OpenSearch (for EKS deployment)
AWS_OPENSEARCH_ENDPOINT=
AWS_OPENSEARCH_REGION=us-east-1

# ====================================
# AWS CONFIGURATION
# ====================================
# AWS region for all services
AWS_REGION=us-east-1

# AWS credentials (DO NOT commit real values)
# In EKS, these will be provided via IAM roles
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=

# ====================================
# LLM CONFIGURATION
# ====================================
# LLM provider: "bedrock", "anthropic", "openai"
LLM_PROVIDER=bedrock
MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# ====================================
# EXTERNAL SERVICES
# ====================================
# GitLab configuration
GITLAB_URL=http://gitlab:80
GITLAB_TOKEN=your-gitlab-token
GITLAB_WEBHOOK_SECRET=your-webhook-secret

# SonarQube configuration
SONAR_HOST_URL=http://sonarqube:9000
SONAR_TOKEN=your-sonar-token
SONARQUBE_WEBHOOK_SECRET=your-sonarqube-secret

# ====================================
# SECURITY CONFIGURATION
# ====================================
# Webhook authentication
WEBHOOK_AUTH_ENABLED=true
WEBHOOK_HMAC_SECRET=your-hmac-secret

# CORS settings (for local development)
CORS_ORIGINS=*

# ====================================
# SERVICE CONFIGURATION
# ====================================
# Service ports (for local development)
WEBHOOK_HANDLER_PORT=8090
STRANDS_AGENT_PORT=8000
STREAMLIT_PORT=8501

# Session management
SESSION_TIMEOUT_MINUTES=240
MAX_SESSIONS_PER_PROJECT=50

# Processing limits
MAX_FIX_ATTEMPTS=3
MAX_LOG_SIZE=30000
MAX_LOG_LINES=1000

# Logging
LOG_LEVEL=INFO

# ====================================
# FEATURE FLAGS
# ====================================
# Enable/disable features for different environments
ENABLE_VECTOR_STORE=true
ENABLE_QUEUE_PROCESSING=true
ENABLE_WEBHOOK_AUTH=true
ENABLE_CORS=true